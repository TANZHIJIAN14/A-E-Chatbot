{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TANZHIJIAN14/A-E-Chatbot/blob/main/A%26E_chatbot__fine_tuning_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ko9zoFeyrij"
      },
      "source": [
        "# Util function and variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VpUVULJ-yq65"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "uncleaned_dataset_path = '/content/sample_data/dataset/'\n",
        "cleaned_dataset_path = '/content/sample_data/cleaned_dataset/'\n",
        "\n",
        "def replace_empty_value(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    # Replace empty strings and other missing value indicators with NaN\n",
        "    df.replace(\"\", np.nan, inplace=True)\n",
        "    return df\n",
        "\n",
        "def remove_columns(file_path, columns_to_remove):\n",
        "    print('Called')\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Remove the specified columns\n",
        "    for column in columns_to_remove:\n",
        "        if column in df.columns:\n",
        "            df = df.drop(columns=[column])\n",
        "\n",
        "    return df\n",
        "\n",
        "def rename_columns(file_path, column_mapping):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Iterate over each key-value pair in the column mapping dictionary\n",
        "    for old_name, new_name in column_mapping.items():\n",
        "        # Check if the old column name exists before renaming\n",
        "        if old_name in df.columns:\n",
        "            # Rename the column\n",
        "            df.rename(columns={old_name: new_name}, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def concat_files(checkFile):\n",
        "    # List to hold DataFrames\n",
        "    dfs = []\n",
        "\n",
        "    # Loop through each CSV file in the directory\n",
        "    for filename in all_processed_files_path:\n",
        "        # Read the CSV file into a DataFrame and append it to the list\n",
        "        to_be_combine_file = filename.split('/')[-1][0:12]\n",
        "        if to_be_combine_file == checkFile:\n",
        "          df = pd.read_csv(filename)\n",
        "          dfs.append(df)\n",
        "\n",
        "          #Remove the file\n",
        "          if os.path.exists(filename):\n",
        "            os.remove(filename)\n",
        "\n",
        "    # Concatenate all DataFrames in the list along the rows axis (axis=0)\n",
        "    if len(dfs) > 0:\n",
        "      return pd.concat(dfs, axis=0, ignore_index=True)\n",
        "    else:\n",
        "      return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RebCd2O-zdyK"
      },
      "source": [
        "# Load file paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E951DC9UzgDs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "all_files_path = glob.glob(os.path.join(uncleaned_dataset_path, \"*.csv\"))\n",
        "all_processed_files_path = glob.glob(os.path.join(cleaned_dataset_path, \"*.csv\"))\n",
        "\n",
        "#'/content/dataset/guideLine.csv'\n",
        "#split -> 'guideLine.csv'\n",
        "all_files_name = [file.split('/')[-1] for file in all_files_path]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYhxKgXwa_Xi"
      },
      "source": [
        "# Replace the empty value with NaN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2ML3K2xbCmf"
      },
      "outputs": [],
      "source": [
        "# List to store cleaned DataFrames\n",
        "cleaned_dfs = []\n",
        "\n",
        "for file_path in all_files_path:\n",
        "    cleaned_df = replace_empty_value(file_path)\n",
        "    cleaned_dfs.append(cleaned_df)\n",
        "\n",
        "# Save each cleaned DataFrame individually and overwrite the original dataset\n",
        "for i, df in enumerate(cleaned_dfs):\n",
        "    df.to_csv(cleaned_dataset_path + all_files_name[i], index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI1Xgt9ass_P"
      },
      "source": [
        "# Remove columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEIUJdYesmcU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Name of column to be removed\n",
        "columns_to_remove = ['web-scraper-order', 'web-scraper-start-url']\n",
        "\n",
        "# List to store cleaned DataFrames\n",
        "cleaned_dfs = []\n",
        "\n",
        "for file_path in all_processed_files_path:\n",
        "    cleaned_df = remove_columns(file_path, columns_to_remove)\n",
        "    cleaned_dfs.append(cleaned_df)\n",
        "\n",
        "\n",
        "# Save each cleaned DataFrame individually and overwrite the original dataset\n",
        "for i, df in enumerate(cleaned_dfs):\n",
        "    df.to_csv(cleaned_dataset_path + all_files_name[i], index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9hvCMM875xU"
      },
      "source": [
        "# Rename column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCK-BlMp78lz"
      },
      "outputs": [],
      "source": [
        "# Define a dictionary of old column names mapped to new column names\n",
        "column_mapping = {\n",
        "    'link': 'linkName',\n",
        "    'link-href': 'link',\n",
        "    'paymentLink': 'paymentName',\n",
        "    'paymentLink-href': 'paymentLink',\n",
        "    'eventLink': 'eventName',\n",
        "    'eventLink-href': 'eventLink',}\n",
        "\n",
        "# List to store cleaned DataFrames\n",
        "cleaned_dfs = []\n",
        "for file_path in all_processed_files_path:\n",
        "    cleaned_df = rename_columns(file_path, column_mapping)\n",
        "    cleaned_dfs.append(cleaned_df)\n",
        "\n",
        "# Save each cleaned DataFrame individually and overwrite the original dataset\n",
        "for i, df in enumerate(cleaned_dfs):\n",
        "    df.to_csv(cleaned_dataset_path + all_files_name[i], index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwThrqJK94fk"
      },
      "source": [
        "# Combine and remove csv files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yBUq-sL_53d"
      },
      "outputs": [],
      "source": [
        "combined_df = concat_files('visitingHour')\n",
        "\n",
        "if combined_df is not None:\n",
        "  # Save the combined DataFrame to a new CSV file\n",
        "  combined_file_path = cleaned_dataset_path + 'allVisitingHour.csv'\n",
        "  combined_df.to_csv(combined_file_path, index=False)\n",
        "\n",
        "# Reset the all cleaned files path\n",
        "all_processed_files_path = glob.glob(os.path.join(cleaned_dataset_path, \"*.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X_tZ2vllQ3E"
      },
      "source": [
        "# Upload cleaned dataset to drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FRUY9fulUGA"
      },
      "outputs": [],
      "source": [
        "# # Step 1: Mount Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Step 2: Upload the CSV file\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# # Step 3: Move the CSV file to Google Drive\n",
        "# import shutil\n",
        "\n",
        "# for filename in all_files_name:\n",
        "#     shutil.move(filename, f'/content/drive/MyDrive/YR3_SEM2/FYP_I/cleaned_dataset/{filename}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcj_7aOesOyO"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_rIXRQlsUev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d65e30-5f97-4bff-c720-885c133bf5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/nightly/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Need to run this once per machine\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U transformers\n",
        "!pip install -q -U accelerate\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U datasets scipy ipywidgets matplotlib\n",
        "\n",
        "# Install PyTorch Nightly with GPU support for Apple Silicon\n",
        "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoRvpasmsIz-"
      },
      "source": [
        "# Basic configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NLRgc6DjsLlI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['HF_HOME'] = \"/content/sample_data/huggingface_home_directory/\"\n",
        "\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAGPs9F-7k0a"
      },
      "source": [
        "# Check torch recognization of my device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sRfpHL_G7uVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add0e104-1070-42f7-89bc-231dd28e68e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MPS device not found.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "#check for gpu\n",
        "if torch.backends.mps.is_available():\n",
        "   mps_device = torch.device(\"mps\")\n",
        "   x = torch.ones(1, device=mps_device)\n",
        "   print (x)\n",
        "else:\n",
        "   print (\"MPS device not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2xHmuNMwXdF"
      },
      "source": [
        "# Authentication of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ubX0whRbwbls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89acedd9-bde2-4e8c-bf87-d37bdcc86581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: fineGrained).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /content/sample_data/huggingface_home_directory/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "# Get a token from Hugging Face\n",
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPoHT3ljw16D"
      },
      "source": [
        "# Set token as env variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4ndQKLKlw6oI"
      },
      "outputs": [],
      "source": [
        "# Set the token as an environment variable\n",
        "os.environ[\"HF_TOKEN\"] = \"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\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiIMXRRxoH0T"
      },
      "source": [
        "# Load Tokenizer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "89PLrigUo5U4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        ")\n",
        "\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "#Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.unk_token\n",
        "tokenizer.pad_token_id =  tokenizer.unk_token_id\n",
        "tokenizer.padding_side = 'left'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtR0cs9fxjR9"
      },
      "source": [
        "# Formatting prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TleVwfXDxlIk"
      },
      "outputs": [],
      "source": [
        "def formatting_func(example):\n",
        "    text = f\"### The following is a doctor's opinion on a person's query: \\n### Patient query: {example['input']} \\n### Doctor opinion: {example['output']}\"\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bACpp1QDxLdn"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbZE5DAYxNgk"
      },
      "outputs": [],
      "source": [
        "max_length = 512 # differs from datasets to datasets\n",
        "\n",
        "# Load all the dataset\n",
        "datasets = []\n",
        "for file_path in all_processed_files_path:\n",
        "    df = pd.read_csv(file_path)\n",
        "    datasets.append(df)\n",
        "\n",
        "# def generate_and_tokenize_prompt(prompt):\n",
        "#     result = tokenizer(\n",
        "#         formatting_func(prompt),\n",
        "#         truncation=True,\n",
        "#         max_length=max_length,\n",
        "#         padding=\"max_length\",\n",
        "#     )\n",
        "#     result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "#     return result\n",
        "\n",
        "# train_dataset = dataset['train']\n",
        "# eval_dataset = dataset['test']\n",
        "# tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
        "# tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)\n",
        "\n",
        "# import pandas as pd\n",
        "# from transformers import AutoTokenizer\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train_tokenize_dataset = []\n",
        "# eval_tokenize_dataset = []\n",
        "\n",
        "# def tokenize_dataset(file):\n",
        "#   # Load the CSV file into a pandas DataFrame\n",
        "#   df = pd.read_csv(file)\n",
        "\n",
        "#   # Function to tokenize a single text column\n",
        "#   def tokenize_column(series, tokenizer):\n",
        "#       return series.apply(lambda x: tokenizer(str(x), padding='max_length', truncation=True, return_tensors='pt'))\n",
        "\n",
        "#   # Apply the tokenizer to all columns\n",
        "#   tokenized_data = {col: tokenize_column(df[col], tokenizer) for col in df.columns}\n",
        "\n",
        "#   # Combine tokenized columns into the DataFrame\n",
        "#   for col in df.columns:\n",
        "#       df[col + '_input_ids'] = tokenized_data[col].apply(lambda x: x['input_ids'].squeeze().tolist())\n",
        "#       df[col + '_attention_mask'] = tokenized_data[col].apply(lambda x: x['attention_mask'].squeeze().tolist())\n",
        "\n",
        "#   # Optionally, drop the original columns if only tokenized data is needed\n",
        "#   df.drop(columns=[col for col in df.columns if not col.endswith('_input_ids') and not col.endswith('_attention_mask')], inplace=True)\n",
        "\n",
        "#   # Define the columns to keep in the split datasets\n",
        "#   tokenized_columns = [col for col in df.columns if col.endswith('_input_ids') or col.endswith('_attention_mask')]\n",
        "\n",
        "#   # Split the dataset\n",
        "#   train_df, eval_df = train_test_split(df[tokenized_columns], test_size=0.2, random_state=42)\n",
        "\n",
        "#   # Optionally reset the index\n",
        "#   train_df.reset_index(drop=True, inplace=True)\n",
        "#   eval_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "#   # Save the training and evaluation DataFrames to CSV files\n",
        "#   train_df.to_csv('train_data.csv', index=False)\n",
        "#   eval_df.to_csv('eval_data.csv', index=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWxc_uOZ3euf"
      },
      "source": [
        "# Load base LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d676e781d1a94426b22cf95c03564ded",
            "e30adaa85ce4423a94e53cf15aa633b4",
            "d5b56aa05a8546b2ae57cd25b7bd3309",
            "62f7beacca5b4ba6aae9d9b519c79ae8",
            "e01561baa7e14c4cb94828c17eaa2686",
            "d8259e9b2ab6492a8ef6d9cb063b48e8",
            "b7a545f48abc411fa9fe12e6602260da",
            "8d170c3e810e4b1fbe05fad418cab415",
            "0af0bd45c9d84c2391cb06852efd69cb",
            "9979f6533ae042e583498d80d85ef974",
            "fa32581465074e9abcbfc81bc8133787"
          ]
        },
        "id": "QMsGrV4K3gjP",
        "outputId": "aa92eab0-404d-4802-a728-8f2368c15a75"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d676e781d1a94426b22cf95c03564ded"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "compute_dtype = getattr(torch, \"float16\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=compute_dtype,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "          model_name, quantization_config=bnb_config, device_map={\"\": 0}\n",
        ")\n",
        "#Configure the pad token in the model\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define prompt for loaded LLM"
      ],
      "metadata": {
        "id": "537gaiOnu6Z0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYwiXY8U5vLU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "64d0ab56-b66b-4755-8c00-d3159049ef92"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9a6e86e6b8ad>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Tokenize the input prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Generate the model output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "# Define the prompt\n",
        "prompt = \"What is LLM?\"\n",
        "\n",
        "# Tokenize the input prompt\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate the model output\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=100,  # Define the maximum length of the generated text\n",
        "        num_return_sequences=1,  # Number of sequences to generate\n",
        "        no_repeat_ngram_size=2,  # Prevent repeating n-grams\n",
        "        early_stopping=True  # Stop early if end of sentence is reached\n",
        "    )\n",
        "\n",
        "# Decode the output to text\n",
        "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(generated_text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1H19-qxO-V8bFG7OwW8hvgRqCATX3WRXQ",
      "authorship_tag": "ABX9TyP63tqwWD31q6YRe6K5yR7G",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d676e781d1a94426b22cf95c03564ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e30adaa85ce4423a94e53cf15aa633b4",
              "IPY_MODEL_d5b56aa05a8546b2ae57cd25b7bd3309",
              "IPY_MODEL_62f7beacca5b4ba6aae9d9b519c79ae8"
            ],
            "layout": "IPY_MODEL_e01561baa7e14c4cb94828c17eaa2686"
          }
        },
        "e30adaa85ce4423a94e53cf15aa633b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8259e9b2ab6492a8ef6d9cb063b48e8",
            "placeholder": "​",
            "style": "IPY_MODEL_b7a545f48abc411fa9fe12e6602260da",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "d5b56aa05a8546b2ae57cd25b7bd3309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d170c3e810e4b1fbe05fad418cab415",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0af0bd45c9d84c2391cb06852efd69cb",
            "value": 0
          }
        },
        "62f7beacca5b4ba6aae9d9b519c79ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9979f6533ae042e583498d80d85ef974",
            "placeholder": "​",
            "style": "IPY_MODEL_fa32581465074e9abcbfc81bc8133787",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "e01561baa7e14c4cb94828c17eaa2686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8259e9b2ab6492a8ef6d9cb063b48e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7a545f48abc411fa9fe12e6602260da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d170c3e810e4b1fbe05fad418cab415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0af0bd45c9d84c2391cb06852efd69cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9979f6533ae042e583498d80d85ef974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa32581465074e9abcbfc81bc8133787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}